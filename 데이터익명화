[출처] 데이터익명화 korea university database laboratory
데이터익명화에 대한 개념과 기술에 대해 설명하는 강의, '데이터 익명화 개념 및 응용' 책을 요약 강의한 동영상 
https://www.youtube.com/watch?v=z9NpnbMj2tg

4. 차분 프라이버시 및 지역 차분 프라이버시 개념 및 활용
differential privacy&Local differential privacy

<차례>
1) 차분 프라이버시의 개념
2) 차분 프라이버시를 이용한 프라이버시 보호 데이터 분석
-> 대화형/비대화형 환경
-> 프라이버시보호 공간 데이터 통계 배포
3) 지역 차분 프라이버시의 개념
4) 지역 차분 프라이버시를 이용한 프라이버시 보호 데이터 수집 및 분석

1) 차분 프라이버시의 개념 

기존 프라이버시 모델들의 한계
1. 구문적(syntactic) 프라이버시 모델의 프라이버시 보호 원칙
구문적 프라이버시 모델? k, l, t 모델
->"공격자가 특정한 수준 이하의 배경지식을 가지고 있다고 가정할 때, 공격자는 배포된 테이블에서 배경지식 이상의 정보를 얻어서는 안된다." 즉, 공격자가 배경지식을 가지고 있을 때, 어떠한 일이 일어나서는 안된다.
원본 데이터를 안전한 데이터로 바꿔야 한다.
2. 구문적 프라이버시 모델이 사용하는 가정의 한계
-> 모든 테이블의 속성은 식별자, 준식별자, 민감 속성으로 나눌 수 있다.
하지만 식별자와 준식별자, 준식별자와 민감 속성을 정학하게 구분하기는 어렵다. 
-> 공격자는 오직 준식별자 속성값만을 배경지식으로 가지고 있다. 
하지만 민감 속성 값도 부분적으로 가질 수 있다.
한계: 구문적 프라이버시 모델은 가정을 기반으로 만들어졌기 때문에 가정을 벗어나게 되면, 위험해질 수 있다.
예시) 공격자는 특정한 사람 한 명을 제외한 모든 사람(n-1명)의 몸무게를 배경지식으로 가지고 있다.
n-1명의 통계적 값(평균값,,)을 통해 특정한 한 사람의 몸무게를 유추할 수 있다. 이러한 것을 하지 못하게 만들어야 한다. symantic 프라이버시의 탄생 배경이다. 

차분 프라이버시 모델의 개념
차분 프라이버시 모델=symantic 프라이버시 모델
Cynthia Dwork가 2006년에 제안한 프라이버시 모델
차분 프라이버시 모델이 가정하는 사항
-> syntactic(k, l, t) 프라이버시 모델은 원본 데이터를 가공해서 배포하는 것이다.
-> symantic 프라이버시 모델은 애초에 원본 데이터베이스를 베포하지 않는다. 
-> 질의를 받아 데이터베이스로부터 결과를 계산하여 반환한다. user->query->database->aswer->user
통계 결과로부터 발생하는 프라이버시 침해를 방어한다.

차분 프라이버시의 정의
1. 인접 데이터베이스(neighboring database)
임의의 두 데이터베이스 D,D'에 대하여 두 데이터베이스가 하나의 레코드 t를 제와한 모든 레코드가 동일 할 때, 인접 데이터베이스 관계에 있다고 정의한다.
공격자가 인접한 데이터베이스를 알고 있더라도 특정 한 사람의 프라이버시가 노출되면 안된다.
2. ε-차분 프라이버시(ε-differential privacy)
데이터베이스로부터 생성한 질의응답 통계 결과를 무작위로 변조하는 메커니즘 A가 다음 식을 만족해야 ε-차분 프라이버시를 보장한다.
Pr[A(D)=S]/Pr[A(D')=S]<=e^ε (ε>=0, S∈Range(A))
"두 인접한 데이터베이스에서 도출한 통계 결과를 변조했을 때, 동일한 결과가 나올 확률의 비율이 크게 차이가 나지 않아야한다."
ε=0, 한 사람의 정보가 D에 있든, D'에 있든 프라이버시가 노출되지 않고, 안전하다는 의미이다. 
ε=무한, 한 사람의 정보가 있는 D의 결과값과 그렇지 않은 D'의 결과값의 차이가 크다면, 그 사람의 프라이버시는 메커지즘 A에 대해 위험하다는 것을 의미한다. 
ε의 값이 클 수록, 프라이버시 위험이 높아진다.
식을 통해 매커니즘 A에 대해 사람의 프라이버시가 위험하다, 안전하다의 정도를 정량적, 수학적으로 표현할 수 있다는 것이 특징이다.

라플라스 메커니즘
결과값에 noise를 추가한다.
1. 차분 프라이버시를 보장하는 기초적인 메커니즘
지수 메커니즘: 질의 결과가 숫자값이 아닌 경우에 사용하는 방법
라플라스 메커니즘: 질의 결과가 숫자값인 경우에 사용하는 방법
2. 라플라스 확률 분포에서 추출한 임의의 실수를 통계 결과에 더해서 변조한다.
3. 임의의 실수를 더하므로 주로 통계 결과가 수와 관련된 값일 경우에 사용된다. 
예)총계(count), 최소(min), 최대(max), 평균(average) 등
user->질의F->데이터베이스 D->실제 결과 F(D)->변조된 결과 F(D)+x (x는 라플라스 분포에서 생성한 임의의 실수)
동일한 질문을 해도 매번 다른 결과값이 나온다.

라플라스 분포의 확률 밀도 함수(probability density function)
f(x|μ,b)=1/2b*e^(|x-μ|/b) μ:평균, 2b^2: 분산

평균 μ=0이고, 분산을 2(Δf/ε)^2로 하는 라플라스 분포를 사용한다.
평균이 0이브로 변조된 결과의 기대값은 실제 결과와 동일하다. 
Δf는 질의 f의 전역 민감도(global sensitivity)를 말한다.
Δf=max|f(D)-f(D')|, 임의의 레코드 하나가 질의 결과에 미칠 수 있는 최대한의 영향력 
예시) count를 사용한다면 D는 100명, D'은 99명의 데이터를 가지고 있다. 이때, Δf는 1이다.
ε=0이면, 여러 값들을 사용하게 되고, ε의 값이 크면 클수록 평균값을 더 빨리 많이 사용한다. 

구성 정리 composition theory
각 단계별 ε값과 전체 ε값의 관계가 무엇인지를 나타낸다
1. 복잡한 알고리즘이 어떠한 차분 프라이버시 보호 기준을 보장하는지 추론하는 것은 어렵다.
2. 알고리즘의 부분이 차분 프라이버시를 만족하는 것을 증명하면 전체 알고르짐의 프라이버시 보호 수준을 알 수 있다. 
3. 순차 구성 정리 
결과값->ε1->결과값->ε2->결과값->ε3->최종결과값
최종 ε값=ε1+ε2+ε3
스무고개와 유사
서로 noise값에 영향을 준다.
4. 병렬 구성 정리 
결과값->ε1->최종 결과값
      ->ε2->최종 결과값
      ->ε3->최종 결과값
최종 ε값=max[ε1,ε2,ε3]
서로 noise값에 영향을 주지 않는다. 
5. 구성 정리 때문에 일반적으로 ε을 "프라이버시 비용(privacy budget)"이라 부른다.
ε의 값이 크면 클수록 퀄리티가 낮아진다. 
퀄리티를 높이기 위해서 적절한 ε의 값을 정해야 한다. 


2) 차분 프라이버시를 이용한 프라이버시 보호 데이터 분석
-> 대화형/비대화형 환경

-대화형 환경- interactive
데이터 분석가->질의 q->데이터베이스 관리자->질의 q->데이터베이스->정확한 결과->데이터베이스 관리자->변조한 결과->데이터 분석가 
데이터베이스 관리자가 데이터베이스와 데이터분석가 사이에 존재한다.
데이터베이스 관리자는 데이터 분석가로부터 질의를 받고 실제 질의 결과를 변조하여 분석가에게 전달한다.
전체 프라이버시 비용을 설정하고 질의 결과를 반환할 때마다 프라이버시 비용을 차감하는 방법을 사용한다. 왜? 순차 구성 정리에 따라 무한정 질의를 받으면 필연적으로 데이터베이스의 모든 정보가 드러난다. 데이터분석사들끼리 질의 결과를 공유할 수 있다.
데이터 분석가는 매번 질의를 할 때마다 다른 결과를 얻는다. 계속 질의를 하다보면 정확한 결과값을 유추할 수 있다. 이때, 데이터베이스 관리자는 질의를 중단한다. 
따라서, 한정된 프라이버시 비용 내에서 많은 질의의 유용성을 보장하는 것이 목표이다. 
대화형 환경은 프라이버시 비용 때문에 비현실적이다.

-비대화형 환경- non-interactive
대화형처럼 질의를 계속 주고받는 것이 아니라 데이터베이스 관리자가 데이터 분석가에게 대량의 데이터를 배포하고, 이를 분석하는 것이다. 
1. 데이터베이스 관리자가 데이터 분석가가 사용할 질의에 따라 합성 데이터(synthetic data)를 생성하여 배포하는 방법이다. 
-> 원본 데이터베이스를 바탕으로 히스토그램(histogram)을 생성하여 배포한다.
-> 원본 데이터베이스의 레코드를 변조한 익명화 데이터베이스(anonymized database)를 배포한다.
-> 원본 데이터베이스를 바탕으로 비슷한 분포(학습)를 가지는 합성 데이터베이스(synthetic database)를 생성하여 배포한다.
2. 히스토그램(통계) 배포
가장 많이 사용하는 방법
-> 데이터베이스의 각 속성을 일정한 구간으로 나누고 특정 구간의 도수에 노이즈를 더해 배포하는 방법
-> 임의의 레코드가 미치는 영향력을 특정 구간으로만 한정할 수 있기 때문에 민감도를 제한할 수 있다는 장점이 있다. 

2) 차분 프라이버시를 이용한 프라이버시 보호 데이터 분석
-> 프라이버시보호 공간 데이터 통계 배포

PPSP(Privacy Preserving Statistics Publishing)
1. 개인들의 공간/위치 데이터에 대한 통계 정보를 배포한다.->다양한 빅데이터 활용
예시) 유동인구 밀집도 분석, 유동인구 기반 노선 최적화, 유동인구 기반 배차간격 조정
2. 위치 정보는 특정한 개인의 거주지, 근무지, 생활 반경 등을 드러내므로 매우 민감한 정보
공격자는 위치 정보를 바탕으로 특정한 개인을 미행, 감시 할 수 있다.

PSD(Private Spatial Decomposition)
프라이버시를 고려해서 공간을 분할하는 것이다. 특정한 개인의 위치가 드러나지 않도록 해야한다. 
전체 공간을 여러 개의 작은 구역으로 나누고 각 구역에 포함된 사람들의 총계에 라플라스 노이즈를 더하여 생성한다. 
PSD에서 점선의 영역 질의(range query)의 총계를 추정한다. 실제 총계와 오차가 있다. 

...이러한 오차를 줄이면서 개인의 프라이버시를 보호할 수 있는 방법이 없을까?

PSD는 임의의 영역 질의에 대해 총계값을 정확하게 추정하는 것을 목표로 한다. 
임의의 영역 질의 q의 유용성은 상대 오차(relative error)을 통해 계산
RelativeError(q)=|RC-NC|/RC
RC(Real Count):실제 총계, NC(Noised Count): PSD를 사용하여 추정한 총계를 의미
PSD에서 오차가 발생하는 원인?
변조 오차(perturbation error): 각 하위 영역에 더해진 라플라스 노이즈에서 발생
비균일성 오차(non-uniformity error): 영역 질의와 부분적으로 겹치는 하위 영역에서 발생, 하위 영역 내에서 사람들이 균등하게 분포하고 있다고 가정하여 추정

PSD 기법의 분류
데이터 비의존적(data-independent)기법: 데이터를 보지 않고, 공간을 구분하는 것, 공간의 크기가 일정하지만 공간 내에 있는 인구 수는 다르거나 같다. 라플라스 노이즈만 고려하면 된다. 하지만 비균일성 오차가 발생할 경우가 많다.  
데이터 의존적(data-dependent) 기법 데이터를 보고 공간을 구분하는 것, 공간의 크기가 일정하지 않지만 공간 내에 있는 인구 수는 모두 동일하다. PSD 비균일 공간으로 인한 에러와 라플라이스 노이즈 둘다 고려해야한다. 대신 비균일성 오차가 줄어든다. 

지역 차분 프라이버시의 개념 및 정의 LDP: Local Differential Privacy<->CDP

지역 차분 프라이버시(ε-local differential privacy)
사용자가 데이터를 가공해서 서버에게 전달한다. 
프라이버시 보호를 위해 서버에는 이미 가공된 데이터를 가지고 있다. 따라서 인접 데이터베이스가 존재하지 않는다.
데이터 수집 환경에서 사용하는 차분 프라이버시 개념 
-> 일반적으로 차분 프라이버시는 데이터베이스 전체를 알고 있어야 하기 때문에 데이터 수집 환경에 적합하지 않는다. 
-> 인접 데이터베이스가 존재하지 않음; 전역민감도 계산 불가능  
다음 식을 만족해야한다.
데이터 제공자가 제공할 수 있는 모든 값의 짝 v1,v2에 대하여 어떤 임의화 알고리즘 A가 다음 식을 만족하면 ε-지역 차분 프라이버시 모델을 만족 한다고 정의한다.
Pr[A(v1)∈R]/Pr[A(v2)∈R]<=e^ε (R⊆Range(A))
ε(ε>=0)은 프라이버시 보호 수준을 결정하는 매개 변수, R은 메커니즘 A가 도출할 수 있는 모든 결과값의 집합

지역 차분 프라이버시 기반 프라이버시 보호 데이터 수집

확률 기반 응답(randomized response)
->1965년에 Warner에 의해 제안된 설문조사 방법
->민감한 사안에 대한 응답을 수집하기 위해 제안된 방법 예) 마약여부, 살인여부처럼 민감한 질문
->확률 기반 응답 수집 방법
1. 응답자가 응답할 때 피응답자가 알지 못하게 동전을 던짐
2. 뒷면이 나오면 진실을 말함
3. 앞면이 나온다면 질문에 관계없이 항상 긍정으로 응답함
4. 수집한 긍정 비율 Y'을 이용하여 실제 긍정비율 Y를 2Y'-1로 추정 가능
개인은 자신의 프라이버시 노출 걱정을 안할 수 있고, 정보를 수집하는 사람은 확률적으로 정확한 통계를 조사할 수 있다.  
->응답의 경우의 수가 두 가지인 이진 데이터 확률 기반 응답 모델은 지역 차분 프라이버시를 만족함이 증명된다.
-> 이때의 ε값은 ln(x/1-x) (x:진실을 대답할 확률)
ε값이 0이면 완벽한 프라이버시를 보장할 수 있다. 

지역 차분 프라이버시 기반 프라이버시 보호 데이터 수집

이진 데이터 확률 기반 응답의 확장
->응답의 경우의 수가 n개인 경우에 대해 확률 기반 응답을 n번 하여 차분 프라이버시르 만족하는 데이터 수집을 할 수 있음 
당신은 1번 응답을 선택했습니까?
당신은 2번 응답을 선택했습니까?
...
당신은 n번 응답을 선택했습니까?
예시) 당신은 어느 회사의 스마트 폰을 사용하십니까?
-당신은 삼성의 스마트폰을 사용하십니까?
-당신은 애플의 스마트폰을 사용하십니까?
-당신은 LG의 스마트폰을 사용하십니까?
-당신은 기타 회사의 스마트폰을 사용하십니까?

지역 차분 프라이버시 기반 프라이버시 보호 데이터 수집
RAPPOR
Randomized aggregatable privacy-preserving ordinal response
2014년 Google에서 발표한 프라이버시 보호 데이터 수집 방법
유한한 경우의 수를 가지는 데이터 수집에 지역 차분 프라이버시를 적용
기존 확률 기반 응답 기법에서 발생하는 문제점 해결
->여러 번의 데이터 수집에서도 차분 프라이버시 보장
->응답의 경우의 수가 많은 경우에도 성능 보장